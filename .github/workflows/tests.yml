name: Tests
run-name: Run tests by @${{ github.actor }}

on:
  push:
    branches:
      - main
  pull_request:


env:
  REGISTRY: ghcr.io
  IMAGE_NAME: kubeai-project/kubeai

jobs:
  build-image:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and export
        uses: docker/build-push-action@v6
        with:
          tags: ghcr.io/kubeai-project/kubeai:test
          outputs: type=docker,dest=${{ runner.temp }}/kubeai.tar

      - name: Upload artifact
        uses: actions/upload-artifact@v5
        with:
          name: kubeai
          path: ${{ runner.temp }}/kubeai.tar

  unit-and-integration:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Run unit tests
        run: make test-unit

      - name: Run integration tests
        run: make test-integration

  e2e-general:
    runs-on: ubuntu-latest
    needs: build-image
    # NOTE: Uncomment if we start getting limited on number of concurrent jobs
    # (due to rapid pushes, etc).
    #needs: unit-and-integration # No use in running e2e tests if integration tests fail.
    strategy:
      matrix:
        testcase:
        - "quickstart"
        - "rollouts"
        - "openai-python-client"
        - "autoscaler-restart-under-load"
        - "autoscaler-restart-no-load"
        - "cache-shared-filesystem"
        - "engine-vllm-pvc"
        - "engine-ollama-pvc"
        - "model-files"
        - "s3-model"
        - "lora-adapter"
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      - name: Download artifact
        uses: actions/download-artifact@v6
        with:
          name: kubeai
          path: ${{ runner.temp }}

      - name: Load image
        run: |
          docker load --input ${{ runner.temp }}/kubeai.tar
          docker image ls -a

      - name: Install kind
        run: |
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.30.0/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind

      - name: Install helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh

      - name: Start kind cluster
        run: kind create cluster

      - name: Load kubeai image in KinD
        run: |
          kind load docker-image ghcr.io/kubeai-project/kubeai:test

      - name: Run the e2e testcase
        run: make test-e2e TEST_CASE=${{ matrix.testcase }}

  e2e-engines:
    runs-on: ubuntu-latest
    needs: build-image
    # NOTE: Uncomment if we start getting limited on number of concurrent jobs
    # (due to rapid pushes, etc).
    #needs: unit-and-integration # No use in running e2e tests if integration tests fail.
    strategy:
      matrix:
        engine: ["fasterwhisper", "infinity"] # "VLLM", "OLlama"
        # Run each test case with and without caching.
        cacheProfile: ["", "e2e-test-kind-pv"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Download artifact
        uses: actions/download-artifact@v6
        with:
          name: kubeai
          path: ${{ runner.temp }}

      - name: Load image
        run: |
          docker load --input ${{ runner.temp }}/kubeai.tar
          docker image ls -a
      - name: Install kind
        run: |
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.30.0/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind

      - name: Install helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh

      - name: Start kind cluster
        run: kind create cluster

      - name: Load kubeai image in KinD
        run: |
          kind load docker-image ghcr.io/kubeai-project/kubeai:test

      - name: Run the e2e testcase
        run: make test-e2e TEST_CASE=engine-${{ matrix.engine }} CACHE_PROFILE=${{ matrix.cacheProfile }}
